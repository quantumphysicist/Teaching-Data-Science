{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['ytick.minor.visible'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer counts the number of times each word appears in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>before</th>\n",
       "      <th>but</th>\n",
       "      <th>dark</th>\n",
       "      <th>deep</th>\n",
       "      <th>go</th>\n",
       "      <th>have</th>\n",
       "      <th>keep</th>\n",
       "      <th>lovely</th>\n",
       "      <th>miles</th>\n",
       "      <th>promises</th>\n",
       "      <th>sleep</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>woods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  are  before  but  dark  deep  go  have  keep  lovely  miles  promises  \\\n",
       "0    1    1       0    0     1     1   0     0     0       1      0         0   \n",
       "1    0    0       0    1     0     0   0     1     1       0      0         1   \n",
       "2    1    0       1    0     0     0   1     0     0       0      1         0   \n",
       "3    1    0       1    0     0     0   1     0     0       0      1         0   \n",
       "\n",
       "   sleep  the  to  woods  \n",
       "0      0    1   0      1  \n",
       "1      0    0   1      0  \n",
       "2      1    0   1      0  \n",
       "3      1    0   1      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "'The woods are lovely, dark and deep',  \n",
    "'But I have promises to keep',   \n",
    "'And miles to go before I sleep',   \n",
    "'And miles to go before I sleep'\n",
    "]\n",
    "# A corpus is a collection of documents\n",
    "# In this case, each document is a string\n",
    "\n",
    "# Initialize a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the corpus of documents\n",
    "# vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpus into a matrix of word counts\n",
    "# X = vectorizer.transform(corpus)\n",
    "\n",
    "# Fit and transform the corpus into a matrix of word counts\n",
    "X = vectorizer.fit_transform(corpus) # is equivalent to vectorizer.fit(corpus).transform(corpus)\n",
    "\n",
    "# Print the resulting matrix of word counts\n",
    "# print(X.toarray())\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "display(df.head())\n",
    "\n",
    "# Notice that the word I is not included in the DataFrame\n",
    "# because the \"default configuration tokenizes the string by extracting words of at least 2 letters.\"\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and         3\n",
       "are         1\n",
       "before      2\n",
       "but         1\n",
       "dark        1\n",
       "deep        1\n",
       "go          2\n",
       "have        1\n",
       "keep        1\n",
       "lovely      1\n",
       "miles       2\n",
       "promises    1\n",
       "sleep       2\n",
       "the         1\n",
       "to          3\n",
       "woods       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum() # axis=0 by default, so it sums across the rows (i.e. each document)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miles</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promises</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woods</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "word           \n",
       "and           3\n",
       "to            3\n",
       "before        2\n",
       "go            2\n",
       "miles         2\n",
       "sleep         2\n",
       "are           1\n",
       "but           1\n",
       "dark          1\n",
       "deep          1\n",
       "have          1\n",
       "keep          1\n",
       "lovely        1\n",
       "promises      1\n",
       "the           1\n",
       "woods         1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A prettier way to display the results:\n",
    "(pd.DataFrame(df.sum(axis=0).\n",
    "             sort_values(ascending=False))\n",
    "             .rename_axis('word')\n",
    "             .rename(columns={0:'count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer is similar to CountVectorizer, but weights the word counts by how often they appear in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>before</th>\n",
       "      <th>but</th>\n",
       "      <th>dark</th>\n",
       "      <th>deep</th>\n",
       "      <th>go</th>\n",
       "      <th>have</th>\n",
       "      <th>keep</th>\n",
       "      <th>lovely</th>\n",
       "      <th>miles</th>\n",
       "      <th>promises</th>\n",
       "      <th>sleep</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>woods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and       are    before       but      dark      deep        go  \\\n",
       "0  1.223144  1.916291  0.000000  0.000000  1.916291  1.916291  0.000000   \n",
       "1  0.000000  0.000000  0.000000  1.916291  0.000000  0.000000  0.000000   \n",
       "2  1.223144  0.000000  1.510826  0.000000  0.000000  0.000000  1.510826   \n",
       "3  1.223144  0.000000  1.510826  0.000000  0.000000  0.000000  1.510826   \n",
       "\n",
       "       have      keep    lovely     miles  promises     sleep       the  \\\n",
       "0  0.000000  0.000000  1.916291  0.000000  0.000000  0.000000  1.916291   \n",
       "1  1.916291  1.916291  0.000000  0.000000  1.916291  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  1.510826  0.000000  1.510826  0.000000   \n",
       "3  0.000000  0.000000  0.000000  1.510826  0.000000  1.510826  0.000000   \n",
       "\n",
       "         to     woods  \n",
       "0  0.000000  1.916291  \n",
       "1  1.223144  0.000000  \n",
       "2  1.223144  0.000000  \n",
       "3  1.223144  0.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define a corpus of text documents\n",
    "corpus = [\n",
    "'The woods are lovely, dark and deep',  \n",
    "'But I have promises to keep',   \n",
    "'And miles to go before I sleep',   \n",
    "'And miles to go before I sleep'\n",
    "]\n",
    "\n",
    "# Initialize a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer(norm=None)  # norm=None to disable normalization, which means that the output won't be normalized to unit length\n",
    "\n",
    "# Fit the vectorizer on the corpus of documents\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpus into a matrix of TF-IDF features\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "# Print the resulting matrix of TF-IDF features\n",
    "#print(X.toarray())\n",
    "\n",
    "# Convert the matrix to a pandas DataFrame\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a much simpler example to understand where these numbers come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first    second  the\n",
       "0  1.405465  0.000000  1.0\n",
       "1  0.000000  1.405465  1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define a corpus of text documents\n",
    "corpus = [\n",
    "'The first',\n",
    "'The second',\n",
    "]\n",
    "# Initialize a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer(norm=None)  # norm=None to disable normalization, which means that the output won't be normalized to unit length\n",
    "\n",
    "# Fit the vectorizer on the corpus of documents\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpus into a matrix of TF-IDF features\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "# Print the resulting matrix of TF-IDF features\n",
    "#print(X.toarray())\n",
    "\n",
    "# Convert the matrix to a pandas DataFrame\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even simpler..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.405465</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first    second\n",
       "0  1.405465  0.000000\n",
       "1  0.000000  1.405465"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define a corpus of text documents\n",
    "corpus = [\n",
    "'first',\n",
    "'second',\n",
    "]\n",
    "# Initialize a TfidfVectorizer object # Equivalent to CountVectorizer followed by TfidfTransformer\n",
    "vectorizer = TfidfVectorizer(norm=False)  # norm=None to disable normalization, which means that the output won't be normalized to unit length\n",
    "\n",
    "# Fit the vectorizer on the corpus of documents\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpus into a matrix of TF-IDF features\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "# Print the resulting matrix of TF-IDF features\n",
    "#print(X.toarray())\n",
    "\n",
    "# Convert the matrix to a pandas DataFrame\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So where do these numbers come from?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf means term-frequency times inverse document-frequency\n",
    "\n",
    "From the sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer):\n",
    "\n",
    "The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.\n",
    "\n",
    "If smooth_idf=True (the default), the constant “1” is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4054651081081644\n"
     ]
    }
   ],
   "source": [
    "# Use the equations in the documentation to work out the maths explicitly\n",
    "\n",
    "n = 2  # n is the number of documents in the corpus\n",
    "df_first = 1  # df in this case is the number of documents in which the word (\"first\") appears\n",
    "\n",
    "#idf1 = np.log(n / df_first) + 1  # smooth_idf=False\n",
    "#print(idf1)\n",
    "\n",
    "idf2 = np.log( (1 + n) / (1 + df_first) ) + 1  # smooth_idf=True (the default)\n",
    "print(idf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
